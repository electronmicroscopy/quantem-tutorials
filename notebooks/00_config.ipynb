{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demonstration of quantEM config for gpus and such. \n",
    "\n",
    "More text to come eventually. \n",
    "\n",
    "Arthur McCray\n",
    "Last remembered to update this line: July 9, 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quantem.core import config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "within the `config` module there is a `config` dictionary that has all the stuff. \n",
    "Access this dictionary with `get` and `set`\n",
    "Can revert to defaults with `refresh`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['has_torch', 'has_cupy', 'device', 'precision', 'dtype_real', 'dtype_complex', 'verbose', 'cupy', 'mkl', 'warnings', 'viz'])\n"
     ]
    }
   ],
   "source": [
    "print(config.config.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important and frequently used parts of config (especially within the quantEM code) are for checking if the environment has `cupy` and `torch`, in order to protect from import errors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "has cupy:  True\n",
      "has torch:  True\n",
      "default device:  cpu\n",
      "set device:  cuda:0\n",
      "device after refresh:  cpu\n",
      "config dict: \n",
      " {'has_torch': True, 'has_cupy': True, 'device': 'cpu', 'precision': 'float32', 'dtype_real': 'float32', 'dtype_complex': 'complex64', 'verbose': 1, 'cupy': {'fft-cache-size': '0 MB'}, 'mkl': {'threads': 2}, 'warnings': {'suppress-all-': False}, 'viz': {'interpolation': 'nearest', 'real_space_units': 'A', 'reciprocal_space_units': 'A^-1', 'cmap': 'gray', 'phase_cmap': 'magma', 'default_colors': '', 'colors': {'set': ['#3A7D44', '#E83F85', '#775AEB', '#ED8607', '#74D4B5', '#808080', '#C51D20', '#7C6A0A', '#00B4D8', '#774936'], 'paired': ['#3A7D44', '#A2C899', '#E83F85', '#FFA5C5', '#775AEB', '#C2B4F4', '#ED8607', '#F9C689', '#74D4B5', '#C2F0DE', '#808080', '#C0C0C0', '#C51D20', '#F28E8E', '#7C6A0A', '#C5B86A', '#00B4D8', '#80D9EB', '#774936', '#B38B7D']}}}\n"
     ]
    }
   ],
   "source": [
    "print(\"has cupy: \", config.get(\"has_cupy\"))\n",
    "print(\"has torch: \", config.get(\"has_torch\"))\n",
    "print(\"default device: \", config.get(\"device\"))  # default device\n",
    "config.set({\"device\": \"gpu\"})  # set device (gpu -> cuda:0)\n",
    "print(\"set device: \", config.get(\"device\"))  # current device\n",
    "config.refresh()  # reset to defaults\n",
    "print(\"device after refresh: \", config.get(\"device\"))\n",
    "print(\"config dict: \\n\", config.config)  # access to the raw dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cupy (and potentially future dask) settings aren't really tested very well, beyond cupy/gpus being available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cupy configs:  {'fft-cache-size': '0 MB'}\n",
      "cupy fft-cache-size:  0 MB\n",
      "set cupy fft-cache-size:  10 MB\n",
      "set cupy fft-cache-size:  10 MB\n"
     ]
    }
   ],
   "source": [
    "print(\"cupy configs: \", config.get(\"cupy\"))  # the cupy specific configs\n",
    "print(\"cupy fft-cache-size: \", config.get(\"cupy.fft-cache-size\"))  # sub-dicts can be gotten with .\n",
    "config.set({\"cupy.fft-cache-size\": \"10 MB\"})\n",
    "# there are equivalent methods of getting using the get method or accessing the config dict directly\n",
    "print(\"set cupy fft-cache-size: \", config.get(\"cupy\")[\"fft-cache-size\"])\n",
    "print(\"set cupy fft-cache-size: \", config.config[\"cupy\"][\"fft-cache-size\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can change the defaults (for this session/kernel) with `config.update_defaults`, this will not be overwritten by `refresh`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cuda:0\n",
      "fft cache:  10 MB\n",
      "Device after refresh:  cuda:0\n",
      "fft cache after refresh:  0 MB\n"
     ]
    }
   ],
   "source": [
    "# set value and default that will be chosen by refresh until kernel is restarted\n",
    "config.update_defaults({\"device\": 0})  # setting gpu with the index also works\n",
    "print(\"Device: \", config.get(\"device\"))\n",
    "print(\"fft cache: \", config.get(\"cupy.fft-cache-size\"))\n",
    "config.refresh()\n",
    "print(\"Device after refresh: \", config.get(\"device\"))\n",
    "print(\"fft cache after refresh: \", config.get(\"cupy.fft-cache-size\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are helpers for accessing the device, as that's the most frequently used part of the config. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:1\n"
     ]
    }
   ],
   "source": [
    "print(config.get(\"device\"))\n",
    "print(config.get_device())\n",
    "print(config.device())\n",
    "config.set_device(1)\n",
    "print(config.device())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "setting defaults or updating the config will throw an error if there isn't a gpu\n",
    "Also the gpu device can be set by passing an integer or a pytorch style device or string  \n",
    "Setting the gpu will set the device for `cupy` as well as the default device for `torch` (i.e. where a tensor goes if you send it `.to(\"cuda\")`), but I prefer to be explicit and send tensors to the named device with `.to(config.get_device)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to set device cuda:5 but found 4 GPUs | has_cupy: True | has_torch: True\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config.update_defaults({\"device\": 1})\n",
    "except ValueError as e:\n",
    "    print(e)\n",
    "\n",
    "try:\n",
    "    config.set({\"device\": \"cuda:5\"})  ## throws an error if only 1 gpu\n",
    "except ValueError as e:\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.refresh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'has_torch': True, 'has_cupy': True},\n",
       " {'device': 'cpu',\n",
       "  'precision': 'float32',\n",
       "  'dtype_real': 'float32',\n",
       "  'dtype_complex': 'complex64',\n",
       "  'verbose': 1,\n",
       "  'cupy': {'fft-cache-size': '0 MB'},\n",
       "  'mkl': {'threads': 2},\n",
       "  'warnings': {'suppress-all-': False},\n",
       "  'viz': {'interpolation': 'nearest',\n",
       "   'real_space_units': 'A',\n",
       "   'reciprocal_space_units': 'A^-1',\n",
       "   'cmap': 'gray',\n",
       "   'phase_cmap': 'magma',\n",
       "   'default_colors': '',\n",
       "   'colors': {'set': ['#3A7D44',\n",
       "     '#E83F85',\n",
       "     '#775AEB',\n",
       "     '#ED8607',\n",
       "     '#74D4B5',\n",
       "     '#808080',\n",
       "     '#C51D20',\n",
       "     '#7C6A0A',\n",
       "     '#00B4D8',\n",
       "     '#774936'],\n",
       "    'paired': ['#3A7D44',\n",
       "     '#A2C899',\n",
       "     '#E83F85',\n",
       "     '#FFA5C5',\n",
       "     '#775AEB',\n",
       "     '#C2B4F4',\n",
       "     '#ED8607',\n",
       "     '#F9C689',\n",
       "     '#74D4B5',\n",
       "     '#C2F0DE',\n",
       "     '#808080',\n",
       "     '#C0C0C0',\n",
       "     '#C51D20',\n",
       "     '#F28E8E',\n",
       "     '#7C6A0A',\n",
       "     '#C5B86A',\n",
       "     '#00B4D8',\n",
       "     '#80D9EB',\n",
       "     '#774936',\n",
       "     '#B38B7D']}}},\n",
       " {'device': 'cuda:0'},\n",
       " {'device': 'cuda:1'},\n",
       " {'device': 'cpu'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.update_defaults({\"device\": \"cpu\"}, config.config)\n",
    "print(config.get(\"device\"))\n",
    "config.defaults  # the defaults are appended (chooses newest preferentially)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### if you want to persist a config change, you can use the write method\n",
    "All of the setting of defaults above is undone if you restart the kernel. When importing it looks for a user config file, and if one exists it will overwrite the quantem defaults with the user defaults. \n",
    "\n",
    "(The default location for the user file is \"~/.config/quantem/config.yaml\", in line with abtem which puts it at \"~/.config/abtem/\". The quantem defaults are stored in \"quantem/core/quantem.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device after refresh:  cpu\n",
      "writing config to: /home/amccray/.config/quantem/config.yaml\n",
      "device after refresh:  cuda:0\n"
     ]
    }
   ],
   "source": [
    "config.refresh()\n",
    "print(\"device after refresh: \", config.get(\"device\"))\n",
    "config.set({\"device\": \"cuda:0\"})\n",
    "config.write()\n",
    "config.refresh()\n",
    "print(\"device after refresh: \", config.get(\"device\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point if you restart the kernel, the default device will still be \"cuda:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from quantem.core import config\n",
    "\n",
    "print(config.device())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this demo we of course don't want to actually set the config, so lets undo that by removing the config file we just made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device after deleting the defaults file and refresh:  cpu\n"
     ]
    }
   ],
   "source": [
    "## reset to defaults by removing the config file\n",
    "configfile = Path(\"~/.config/quantem/config.yaml\").expanduser()\n",
    "configfile.unlink()\n",
    "config.refresh()\n",
    "print(\"device after deleting the defaults file and refresh: \", config.get(\"device\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## demo of working with multiple gpus and torch/cupy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "available gpus:  4\n"
     ]
    }
   ],
   "source": [
    "import cupy as cp\n",
    "import torch\n",
    "from quantem.core import config\n",
    "\n",
    "print(\"available gpus: \", torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config device:  cpu\n",
      "arr0 is on the default cupy device, when config is cpu -> gpu0:  <CUDA Device 0>\n",
      "setting config to gpu 1:  cuda:1\n",
      "this does not change the arr0 device, which is still:  <CUDA Device 0>\n",
      "arr1 is on the new device:  <CUDA Device 1>\n"
     ]
    }
   ],
   "source": [
    "config.refresh()\n",
    "print(\"config device: \", config.get(\"device\"))\n",
    "arr0 = cp.arange(5)\n",
    "print(\"arr0 is on the default cupy device, when config is cpu -> gpu0: \", arr0.device)\n",
    "config.set({\"device\": 1})\n",
    "print(\"setting config to gpu 1: \", config.get(\"device\"))\n",
    "print(\"this does not change the arr0 device, which is still: \", arr0.device)\n",
    "arr1 = cp.arange(5)\n",
    "print(\"arr1 is on the new device: \", arr1.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working with cupy arrays on multiple devices will raise warnings (and probably give incorrect results)\n",
      "arrsum is on the new device:  <CUDA Device 1>\n",
      "but the values aren't correct\n",
      "arr0:  [0 1 2 3 4]\n",
      "arr1:  [0 1 2 3 4]\n",
      "arrsum:  [-1  0  1  2  3]\n",
      "note that we do get a performance warning from cupy, but it is not an error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2215707/1519630146.py:2: PerformanceWarning: The device where the array resides (0) is different from the current device (1). Peer access has been activated automatically.\n",
      "  arrsum = arr0 + arr1\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"working with cupy arrays on multiple devices will raise warnings (and probably give incorrect results)\"\n",
    ")\n",
    "arrsum = arr0 + arr1\n",
    "print(\"arrsum is on the new device: \", arrsum.device)\n",
    "\n",
    "print(\"but the values aren't correct\")\n",
    "print(\"arr0: \", arr0)\n",
    "print(\"arr1: \", arr1)\n",
    "print(\"arrsum: \", arrsum)\n",
    "print(\"note that we do get a performance warning from cupy, but it is not an error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So basically, set the gpu device with `config.set({\"device\": XX})` before you start working with `cupy` arrays. \n",
    "\n",
    "With `torch` you have to explicitly set the tensor device either upon initialization or by moving the array, so changing the config is less of an issue. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t1 device:  cpu\n",
      "t1 device:  cuda:1\n",
      "t1 device:  cpu\n",
      "t2 is built on the gpu:  cuda:1\n",
      "setting the config device will set where the default 'cuda' sends the tensor, but it's better to be explicit\n",
      "t3 device:  cuda:1\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.tensor([1, 2, 3])\n",
    "print(\"t1 device: \", t1.device)\n",
    "t1 = t1.to(config.device())\n",
    "print(\"t1 device: \", t1.device)\n",
    "t1 = t1.cpu()\n",
    "print(\"t1 device: \", t1.device)\n",
    "t2 = torch.tensor([4, 5, 6], device=config.device())\n",
    "print(\"t2 is built on the gpu: \", t2.device)\n",
    "t3 = t1.cpu()\n",
    "print(\n",
    "    \"setting the config device will set where the default 'cuda' sends the tensor, but it's better to be explicit\"\n",
    ")\n",
    "t3 = t3.to(\"cuda\")\n",
    "print(\"t3 device: \", t3.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- end -- "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
