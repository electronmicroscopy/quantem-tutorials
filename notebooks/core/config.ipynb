{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demonstration of quantEM config for gpus and such. \n",
    "\n",
    "Requirements: \n",
    "- This notebook requires an available GPU(s) or apple silicon MPS (MPS is largely untested but should work)\n",
    "\n",
    "Arthur McCray\n",
    "December 17, 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quantem.core import config\n",
    "import torch "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most common use for `config` is setting and getting the default device. Laptops will have at maximum one gpu, or some apple devices have `mps`. In these cases it is rather simple to keep track of which device is being used, but for servers and workstations with multiple gpus it is important to specify which gpu to use.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch cuda is available: True\n",
      "Number of GPUs available: 4\n",
      "GPU names: ['NVIDIA L40S', 'NVIDIA L40S', 'NVIDIA L40S', 'NVIDIA L40S']\n",
      "Torch mps is available: False\n"
     ]
    }
   ],
   "source": [
    "print(f\"Torch cuda is available: {torch.cuda.is_available()}\")\n",
    "print(f\"Number of GPUs available: {torch.cuda.device_count()}\")\n",
    "print(f\"GPU names: {[torch.cuda.get_device_name(i) for i in range(torch.cuda.device_count())]}\")\n",
    "print(f\"Torch mps is available: {torch.backends.mps.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will proceed with selecting the first gpu (index 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default device:  cpu\n",
      "set device:  cuda:0\n",
      "device after refresh:  cpu\n"
     ]
    }
   ],
   "source": [
    "print(\"default device: \", config.get(\"device\"))  \n",
    "config.set({\"device\":0})  # set device \n",
    "print(\"set device: \", config.get(\"device\"))  # current device, torch string format\n",
    "config.refresh()  # reset to defaults\n",
    "print(\"device after refresh: \", config.get(\"device\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are helpers for accessing the default compute device, as that's the most frequently used part of the config. \n",
    "\n",
    "You can set the default device by passing an integer (corresponding to the GPU index), a `torch.device` object, or a `torch`-style string, e.g. `\"cuda:0\"` to specify the first GPU.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial device: cpu | cpu\n",
      "device after setting: cuda:0\n",
      "device after refresh: cpu\n"
     ]
    }
   ],
   "source": [
    "### ways to get the current device\n",
    "print(f\"Initial device: {config.get('device')} | {config.get_device()}\")\n",
    "\n",
    "### ways to set the device\n",
    "### any of the following will work\n",
    "config.set_device(0) # integer index of the gpu\n",
    "config.set_device(\"cuda:0\") # torch-style string\n",
    "config.set_device(torch.device(0)) # torch device object\n",
    "# config.set_device(\"mps\") # if using an apple device with mps\n",
    "\n",
    "print(f\"device after setting: {config.get_device()}\")\n",
    "\n",
    "### reset to defaults\n",
    "config.refresh()\n",
    "print(f\"device after refresh: {config.get_device()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default device determines where a `torch` tensor will be sent if you set its device as `\"cuda\"`. However it is generally preferable to be explicit and send tensors to the named device with `.to(config.get_device)`. \n",
    "\n",
    "A couple of other notes: \n",
    "- Setting defaults or updating the config will throw an error if there isn't a gpu at the index specified \n",
    "- Setting the device will also specify the gpu used by `cupy` if it is in your environment.\n",
    "    - `cupy` is no longer a dependency of quantEM, but it's part of why the config was written in the first place. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting quantem device:  cpu\n",
      "tensor created on:  cpu\n",
      "tensor moved to `cuda` lands on:  cuda:0\n",
      "quantem device set to:  cuda:1  (torch tensors are still created on cpu unless otherwise specified)\n",
      "tensor moved to `cuda` lands on:  cuda:1\n"
     ]
    }
   ],
   "source": [
    "print(\"starting quantem device: \", config.get_device())\n",
    "t = torch.arange(5)\n",
    "print(\"tensor created on: \", t.device)\n",
    "t = t.to(\"cuda\")\n",
    "print(\"tensor moved to `cuda` lands on: \", t.device)\n",
    "\n",
    "try:\n",
    "    config.set({\"device\": 1})\n",
    "except RuntimeError as e:\n",
    "    print(\"Only 1 gpu available, so this fails\")\n",
    "    \n",
    "print(\"quantem device set to: \", config.get_device(), \" (torch tensors are still created on cpu unless otherwise specified)\")\n",
    "t = t.to(\"cuda\")\n",
    "print(\"tensor moved to `cuda` lands on: \", t.device)\n",
    "config.refresh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only 4 gpus available, so this fails with:\n",
      "'''\n",
      "CUDA error: invalid device ordinal\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "'''\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config.set_device(4)  ## throws an error if only 1 gpu\n",
    "except RuntimeError as e:\n",
    "    print(f\"Only {torch.cuda.device_count()} gpus available, so this fails with:\\n'''\\n{e}'''\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can change the defaults (for this session/kernel) with `config.update_defaults`, this will not be overwritten by `refresh`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting defaults: device=cpu | dtype_real=float32\n",
      "updating the default device to cuda:0 and changing dtype_real (without updating the default) to float64\n",
      "before refresh: device=cuda:0 | dtype_real=float64\n",
      "after refresh:  device=cuda:0 | dtype_real=float32\n"
     ]
    }
   ],
   "source": [
    "print(f\"starting defaults: device={config.get('device')} | dtype_real={config.get('dtype_real')}\")  \n",
    "config.update_defaults({\"device\": 0})  # setting gpu with the index also works\n",
    "config.set({\"dtype_real\": \"float64\"})  \n",
    "print(f\"updating the default device to {config.get('device')} and changing dtype_real (without updating the default) to {config.get('dtype_real')}\")  \n",
    "print(f\"before refresh: device={config.get('device')} | dtype_real={config.get('dtype_real')}\")\n",
    "config.refresh()  # reset to defaults\n",
    "print(f\"after refresh:  device={config.get('device')} | dtype_real={config.get('dtype_real')}\")\n",
    "config.update_defaults({\"device\": \"cpu\"})  # setting back to original defaults\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### if you want to persist a config change, you can use the write method\n",
    "Setting the defaults using `update_defaults` does not persist if you restart the kernel. It just updates the current defaults and therefore changes what is reset when calling `config.refresh()`. \n",
    "\n",
    "The defaults are initially defined on import when the nmodule looks for a user-specified config file. If one exists it will overwrite the quantem defaults with the user defaults. \n",
    "\n",
    "(The default location for the user file is \"~/.config/quantem/config.yaml\", in line with abtem which puts it at \"~/.config/abtem/\". The quantem defaults are stored in \"quantem/core/quantem.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device after refresh:  cpu\n",
      "writing config to:  /home/amccray/.config/quantem/config.yaml\n",
      "device after refresh:  cuda:0\n"
     ]
    }
   ],
   "source": [
    "config.refresh()\n",
    "print(\"device after refresh: \", config.get(\"device\"))\n",
    "config.set({\"device\": \"cuda:0\"})\n",
    "config.write()\n",
    "config.refresh()\n",
    "print(\"device after refresh: \", config.get(\"device\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point if you restart the kernel, the default device will still be \"cuda:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from quantem.core import config\n",
    "\n",
    "print(config.device())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this demo we of course don't want to actually set the config, so lets undo that by removing the config file we just made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device after deleting the defaults file and refresh:  cpu\n"
     ]
    }
   ],
   "source": [
    "## reset to defaults by removing the config file\n",
    "configfile = Path(\"~/.config/quantem/config.yaml\").expanduser()\n",
    "configfile.unlink()\n",
    "config.refresh()\n",
    "print(\"device after deleting the defaults file and refresh: \", config.get(\"device\"))\n",
    "\n",
    "## we could also just reset the config to defaults by setting the device to \"cpu\"\n",
    "## but this would leave the config file in place, so we'll delete it instead\n",
    "# config.set_device(\"cpu\")\n",
    "# config.write()\n",
    "# config.refresh()\n",
    "# print(\"device after deleting the defaults file and refresh: \", config.get(\"device\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other stuff in config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Internally, within the `config` module there is a `config.config` dictionary that keeps track of all settings (default or user specified). You can access this with `config.get` and `config.set`, or by directly looking at the `config.config` dictionary.  \n",
    "Can revert to defaults with `refresh`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`quantEM` now has `torch` as a required dependency, and does not require `cupy`. This was not always the case, and you can therefore use the config to check if the environment has `cupy` and `torch`, in order to protect from import errors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "has cupy:  False\n",
      "has torch:  True\n"
     ]
    }
   ],
   "source": [
    "print(\"has cupy: \", config.get(\"has_cupy\"))\n",
    "print(\"has torch: \", config.get(\"has_torch\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see all the things specified in `config` by looking directly at the dictionary: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'has_torch': True,\n",
       " 'has_cupy': False,\n",
       " 'device': 'cpu',\n",
       " 'precision': 'float32',\n",
       " 'dtype_real': 'float32',\n",
       " 'dtype_complex': 'complex64',\n",
       " 'verbose': 1,\n",
       " 'cupy': {'fft-cache-size': '0 MB'},\n",
       " 'mkl': {'threads': 2},\n",
       " 'warnings': {'suppress-all-': False},\n",
       " 'viz': {'interpolation': 'nearest',\n",
       "  'real_space_units': 'A',\n",
       "  'reciprocal_space_units': 'A^-1',\n",
       "  'cmap': 'gray',\n",
       "  'phase_cmap': 'magma',\n",
       "  'default_colors': '',\n",
       "  'colors': {'set': ['#3A7D44',\n",
       "    '#E83F85',\n",
       "    '#775AEB',\n",
       "    '#ED8607',\n",
       "    '#74D4B5',\n",
       "    '#808080',\n",
       "    '#C51D20',\n",
       "    '#7C6A0A',\n",
       "    '#00B4D8',\n",
       "    '#774936'],\n",
       "   'paired': ['#3A7D44',\n",
       "    '#A2C899',\n",
       "    '#E83F85',\n",
       "    '#FFA5C5',\n",
       "    '#775AEB',\n",
       "    '#C2B4F4',\n",
       "    '#ED8607',\n",
       "    '#F9C689',\n",
       "    '#74D4B5',\n",
       "    '#C2F0DE',\n",
       "    '#808080',\n",
       "    '#C0C0C0',\n",
       "    '#C51D20',\n",
       "    '#F28E8E',\n",
       "    '#7C6A0A',\n",
       "    '#C5B86A',\n",
       "    '#00B4D8',\n",
       "    '#80D9EB',\n",
       "    '#774936',\n",
       "    '#B38B7D']}}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some vizualization defaults in config that can be changed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'interpolation': 'nearest',\n",
       " 'real_space_units': 'A',\n",
       " 'reciprocal_space_units': 'A^-1',\n",
       " 'cmap': 'gray',\n",
       " 'phase_cmap': 'magma',\n",
       " 'default_colors': '',\n",
       " 'colors': {'set': ['#3A7D44',\n",
       "   '#E83F85',\n",
       "   '#775AEB',\n",
       "   '#ED8607',\n",
       "   '#74D4B5',\n",
       "   '#808080',\n",
       "   '#C51D20',\n",
       "   '#7C6A0A',\n",
       "   '#00B4D8',\n",
       "   '#774936'],\n",
       "  'paired': ['#3A7D44',\n",
       "   '#A2C899',\n",
       "   '#E83F85',\n",
       "   '#FFA5C5',\n",
       "   '#775AEB',\n",
       "   '#C2B4F4',\n",
       "   '#ED8607',\n",
       "   '#F9C689',\n",
       "   '#74D4B5',\n",
       "   '#C2F0DE',\n",
       "   '#808080',\n",
       "   '#C0C0C0',\n",
       "   '#C51D20',\n",
       "   '#F28E8E',\n",
       "   '#7C6A0A',\n",
       "   '#C5B86A',\n",
       "   '#00B4D8',\n",
       "   '#80D9EB',\n",
       "   '#774936',\n",
       "   '#B38B7D']}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.get('viz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- end -- "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
